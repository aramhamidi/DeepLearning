{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Classification on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prepration\n",
    "first thing to do, we downlaod the mnist dataset from sklearn datasets. We also need to know what kind of data we are dealing with and answer questions like how many samples do we have, what is the shape of each sample , etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aramhamidi/scikit_learn_data\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets.base import get_data_home \n",
    "print (get_data_home())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COL_NAMES': ['label', 'data'],\n",
       " 'DESCR': 'mldata.org dataset: mnist-original',\n",
       " 'data': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
       " 'target': array([ 0.,  0.,  0., ...,  9.,  9.,  9.])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the description, data is containing one row per instance and one column per feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "x,y = mnist['data'],mnist['target']\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "number of images are 70000 and we have 784 features per sample. 784 is coming from the fact that images are 28 by 28 pixels and each pixel counts as a feature. Now let's look at some of those sample images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label of this image is  3.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUIQfCIrwA0ERfiCo/wfGk4GzNig4pwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f12b3cfc0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "picked_sample = x[22000]\n",
    "picked_sample_image = picked_sample.reshape(28,28)\n",
    "print('label of this image is ',y[22000])\n",
    "plt.imshow(picked_sample_image, cmap=matplotlib.cm.binary, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Test and Validation sets\n",
    "mnist dataset is already splited in to training set, which is the first 60000 images, and also test set whih is the last 10000 images. However we need to shuffle the training set to garantee that our training dataset is random enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = x[:60000], y[:60000], x[60000:], y[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "shuffle_index = np.random.permutation(60000)\n",
    "x_train, y_train = x_train[shuffle_index], y_train[shuffle_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Binary Classifier\n",
    "This is the first classifier, we are going to explor. Binary classifier in this case can detec one digit among the others. It acts like a Buzzer, whenever it finds a *'3'* for example, it Buzzez that it found one. Of course if it trains well. Otherwise it won't be able to find any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In our binary classifier we only care about two kind of labels: 1 (for digits == 3 and 0 (for digits != 3)\n",
    "y_train_3 = (y_train == 3)\n",
    "y_test_3 = (y_test == 3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our dataset is fairly large, let's use SGD classierfier. SGD classifiers are also very efficient for online training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=42, shuffle=True, verbose=0,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "# since we want some reproducable results, we set the random_state parameter\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(x_train, y_train_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True], dtype=bool)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.predict([picked_sample])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That sweet \"True\" up here means that our classifier thinks out picked_sample is a 3, which is correct! But we can't get too excited too early. Let's see how is the actuall performance of our classifier. We have so many different performance measures to work with such as:\n",
    "1.Measuring accuracy with Cross-Validation\n",
    "2.Confusion Matrix\n",
    "3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring Accuracy with Cross-Validation\n",
    "There are many different ways to do cross-validation. Here we will a K-fold cross-validation, meaning to split the training set into K folds, then chose one fold to evaluate the trained model on other folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.9680016  0.96225    0.9640482]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# we pick 3 folds\n",
    "folds_validation = cross_val_score(sgd_clf, x_train, y_train_3, cv=3, scoring='accuracy')\n",
    "print(folds_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shall we now get excited? Let's see how a simple classifier does on the images that are not 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.09875,  0.0984 ,  0.099  ])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "class notA3Classifier(BaseEstimator):\n",
    "    def fit(self, x, y=None):\n",
    "        pass\n",
    "    def predict(self, x):\n",
    "        return np.zeros((len(x),1 ), dtype=bool)\n",
    "\n",
    "not3_clf = notA3Classifier()\n",
    "cross_val_score(not3_clf, x_train, y_train, cv=3, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the answer is no, dont get too exited. It also makes sence sice only 10% of the data is '3'. So even if this classifier always predicts that the data is not a '3' it is correct 90% of the times!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "Accuracy is not always the best metric to measure the performance. Specially when we are dealing with skewed datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matix\n",
    "The idea is to see how many times a sample of class A has been classified as class B (meaning classifier got confused!). In this case you can look at the row A and column B of the confusion matrix.\n",
    "We need predictions, but not on test set, cause we want to keep it untouched for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "#cross_val_predict performs similar to cross_val_score but returns predictions instead of evaluation scores.\n",
    "y_train_pred = cross_val_predict(sgd_clf, x_train, y_train_3, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that sgd_clf is not trained on the same dataset.(y_train_3 not y_train). So the predictions here are clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[52971,   898],\n",
       "       [ 1216,  4915]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "CM = confusion_matrix(y_train_3, y_train_pred)\n",
    "CM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First row is for *negative class* or *not-3* digits and the second or is for *positive class*.\n",
    "So as you can see, the classifier has been wrongly classifying non 3 digits as 3, 898 times and also 3 digits as not-3, 1216 times. So we can say:\n",
    "\n",
    "  FN(True Positive) = 1216\n",
    "  \n",
    "  TN(True Negative) = 52971\n",
    "\n",
    "  FP(False Positive) = 898\n",
    "\n",
    "  TP(False Negative) = 4915"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pricision of classifier: 0.845518665061\n"
     ]
    }
   ],
   "source": [
    "classifier_precision = CM[1][1] / (CM[1][1]  + CM[0][1])  \n",
    "print('pricision of classifier:', classifier_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensitivity, or recall of classifier: 0.801663676399\n"
     ]
    }
   ],
   "source": [
    "classifier_recall = CM[1][1] / (CM[1][1]  + CM[1][0])  \n",
    "print('sensitivity, or recall of classifier:', classifier_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision with skearn: 0.845518665061\n",
      "recall with sklearn 0.801663676399\n",
      "F1-score of classifier 0.823007367716\n"
     ]
    }
   ],
   "source": [
    "# We can se sklearn to calculate these metrics as well\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "print('precision with skearn:',precision_score(y_train_3, y_train_pred))\n",
    "print('recall with sklearn', recall_score(y_train_3, y_train_pred))\n",
    "print('F1-score of classifier', f1_score(y_train_3, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our classifier precision in detecting 3-digit is only 84% and it can detect digit-3 only 80% of the times. Not very impressive to get excited about. And F1 score is high only when both presicion and sensitivity are high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
